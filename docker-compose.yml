# docker-compose.yml
version: '3.8'

services:
  # 1. Zookeeper: Required by Kafka for coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      # This line has been corrected
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # 2. Kafka: The message broker (our "Mailbox")
  kafka:
    image: confluentinc/cp-kafka:7.5.3
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  # 3. Hadoop NameNode: The master for HDFS (our "Library Head")
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - "9870:9870" # Web UI for HDFS
    environment:
      - CLUSTER_NAME=mycluster
    volumes:
      - hadoop_namenode_data:/hadoop/dfs/name

  # 4. Hadoop DataNode: The storage worker for HDFS (our "Library Shelves")
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    depends_on:
      - namenode
    volumes:
      - hadoop_datanode_data:/hadoop/dfs/data

  # 5. Samza Runner: A container to build and run our Java job
  samza-runner:
    image: maven:3.8-openjdk-11
    container_name: samza-runner
    depends_on:
      - kafka
    volumes:
      # Mount our local code directory into the container
      - ./samza-realtime-job:/usr/src/app
      # This will persist the Maven cache
      - maven_cache:/root/.m2
    working_dir: /usr/src/app
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...' &&
        sleep 30 &&
        echo 'Building and running Samza job...' &&
        mvn clean package &&
        java -Djob.config.loader.factory=org.apache.samza.config.loaders.PropertiesConfigLoaderFactory -Djob.config.factory=org.apache.samza.config.factories.PropertiesConfigFactory -Djob.config.path=file://$PWD/src/main/config/my-realtime-job.properties -cp target/samza-realtime-job.jar org.apache.samza.job.JobRunner
      "

# Define persistent volumes
volumes:
  hadoop_namenode_data:
  hadoop_datanode_data:
  # This declares the new volume
  maven_cache:
